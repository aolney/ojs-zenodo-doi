{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# OJS Zenodo DOI\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "The purpose of this notebook is to generate [Zenodo](https://zenodo.org/) [DOIs](https://www.doi.org/) for the [Open Journal Systems](https://pkp.sfu.ca/ojs/) publishing system.\n",
    "\n",
    "DOIs historically have had a monetary cost that an open access, no publication fee journal may find unsupportable.\n",
    "\n",
    "Zenodo solves this problem by providing DOIs free of charge and permanently archiving journal publications at the same time. [Zenodo is an initiative for open science funded and maintained by EU as part of CERN](https://en.wikipedia.org/wiki/Zenodo).\n",
    "\n",
    "This notebook requires Jupyter with [F# support](https://github.com/fsprojects/IfSharp), which may require [additional installation of libraries depending on your operating system](https://fsharp.org/).\n",
    "Alternatively, this notebook can be used in the web browser without installing any software through the [Azure Notebooks](https://notebooks.azure.com/) service.\n",
    "Additional libraries include [F# Data](https://fsharp.github.io/FSharp.Data/) and [Json.NET](https://www.newtonsoft.com/json).\n",
    "\n",
    "The focus of this notebook is to upload extract the relevant metadata from OJS, upload the metadata and journal articles to Zenodo, and obtain DOIs through the [Zenodo API](https://developers.zenodo.org/#rest-api).\n",
    "\n",
    "The following example JSON was obtained by first loading an article manually and then using the GET query below to pull the metadata.\n",
    "Some of this serves as a model for using the API to populate Zenodo, though some is supplied by Zenodo itself.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"conceptdoi\": \"10.5281/zenodo.3344810\",\n",
    "  \"conceptrecid\": \"3344810\",\n",
    "  \"created\": \"2019-07-20T19:22:01.952843\",\n",
    "  \"doi\": \"10.5281/zenodo.3344873\",\n",
    "  \"doi_url\": \"https://doi.org/10.5281/zenodo.3344873\",\n",
    "  \"files\": [\n",
    "    {\n",
    "      \"checksum\": \"73046695232d27a9d4ebfce51db70dfe\",\n",
    "      \"filename\": \"kai-1.0.1.pdf\",\n",
    "      \"filesize\": 633528,\n",
    "      \"id\": \"bf09b35e-858d-47c9-82d7-45c404dd4b27\",\n",
    "      \"links\": {\n",
    "        \"download\": \"https://zenodo.org/api/files/1a8f04d8-e135-418a-8d85-47ea01148309/kai-1.0.1.pdf\",\n",
    "        \"self\": \"https://zenodo.org/api/deposit/depositions/3353411/files/bf09b35e-858d-47c9-82d7-45c404dd4b27\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"id\": 3344873,\n",
    "  \"links\": {\n",
    "    \"badge\": \"https://zenodo.org/badge/doi/10.5281/zenodo.3344873.svg\",\n",
    "    \"bucket\": \"https://zenodo.org/api/files/e3c269ac-be62-447b-b1b8-1f9992773de7\",\n",
    "    \"conceptbadge\": \"https://zenodo.org/badge/doi/10.5281/zenodo.3344810.svg\",\n",
    "    \"conceptdoi\": \"https://doi.org/10.5281/zenodo.3344810\",\n",
    "    \"discard\": \"https://zenodo.org/api/deposit/depositions/3344873/actions/discard\",\n",
    "    \"doi\": \"https://doi.org/10.5281/zenodo.3344873\",\n",
    "    \"edit\": \"https://zenodo.org/api/deposit/depositions/3344873/actions/edit\",\n",
    "    \"files\": \"https://zenodo.org/api/deposit/depositions/3344873/files\",\n",
    "    \"html\": \"https://zenodo.org/deposit/3344873\",\n",
    "    \"latest\": \"https://zenodo.org/api/records/3344873\",\n",
    "    \"latest_html\": \"https://zenodo.org/record/3344873\",\n",
    "    \"publish\": \"https://zenodo.org/api/deposit/depositions/3344873/actions/publish\",\n",
    "    \"record\": \"https://zenodo.org/api/records/3344873\",\n",
    "    \"record_html\": \"https://zenodo.org/record/3344873\",\n",
    "    \"self\": \"https://zenodo.org/api/deposit/depositions/3344873\"\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"access_right\": \"open\",\n",
    "    \"creators\": [\n",
    "      {\n",
    "        \"affiliation\": \"Teachers College, Columbia University\",\n",
    "        \"name\": \"Kai, Shimin\"\n",
    "      },\n",
    "      {\n",
    "        \"affiliation\": \"Teachers College, Columbia University\",\n",
    "        \"name\": \"Almeda, Victoria\"\n",
    "      },\n",
    "      {\n",
    "        \"affiliation\": \"University of Pennsylvania\",\n",
    "        \"name\": \"Baker, Ryan S.\"\n",
    "      },\n",
    "      {\n",
    "        \"affiliation\": \"Worcester Polytechnic Institute\",\n",
    "        \"name\": \"Heffernan, Cristina\"\n",
    "      },\n",
    "      {\n",
    "        \"affiliation\": \"Worcester Polytechnic Institute\",\n",
    "        \"name\": \"Heffernan, Neil\"\n",
    "      }\n",
    "    ],\n",
    "    \"description\": \"<p>Research on non-cognitive factors has shown that persistence in the face of challenges plays an important role in learning. However, recent work on wheel-spinning, a type of unproductive persistence where students spend too much time struggling without achieving mastery of skills, show that not all persistence is uniformly beneficial for learning. For this reason, it becomes increasingly pertinent to identify the key differences between unproductive and productive persistence toward informing interventions in computer-based learning environments. In this study, we use a classification model to distinguish between productive persistence and wheel-spinning in ASSISTments, an online math learning platform. Our results indicate that there are two types of students who wheel-spin: first, students who do not request any hints in at least one problem but request more than one bottom-out hint across any 8 problems in the problem set; second, students who never request two or more bottom out hints across any 8 problems, do not request any hints in at least one problem, but who engage in relatively short delays between solving problems of the same skill. These findings suggest that encouraging students to both engage in spaced practice and use bottom-out hints sparingly is likely helpful for reducing their wheel-spinning and improving learning. These findings also provide insight on when students are struggling and how to make students&#39; persistence more productive.</p>\",\n",
    "    \"doi\": \"10.5281/zenodo.3344873\",\n",
    "    \"journal_issue\": \"1\",\n",
    "    \"journal_pages\": \"36-71\",\n",
    "    \"journal_title\": \"Journal of Educational Data Mining\",\n",
    "    \"journal_volume\": \"10\",\n",
    "    \"keywords\": [\n",
    "      \"predictive modeling\",\n",
    "      \"wheel-spinning\",\n",
    "      \"productive persistence\",\n",
    "      \"decision tree\",\n",
    "      \"intelligent tutoring system\"\n",
    "    ],\n",
    "    \"language\": \"eng\",\n",
    "    \"license\": \"CC-BY-NC-ND-4.0\",\n",
    "    \"notes\": \"Erratum for Kai, S., Almeda, M.V., Baker, R.S., Heffernan, C., Heffernan, N. (2018) Decision Tree Modeling of Wheel-Spinning and Productive Persistence in Skill Builders. Journal of Educational Data Mining, 10 (1), 36-71.\\n\\nIn the original published version of the article, it was stated that student-level cross-validation was used. However, upon later re-analysis by another member of our laboratory, Yeyu Wang, it was determined that cross-validation had been inadvertently conducted at the level of student-skill pairs. When the overall model was re-validated using student-level cross-validation, the overall model's goodness dropped by just under 0.05 (AUC ROC), from 0.684 to 0.636.\",\n",
    "    \"prereserve_doi\": {\n",
    "      \"doi\": \"10.5281/zenodo.3344873\",\n",
    "      \"recid\": 3344873\n",
    "    },\n",
    "    \"publication_date\": \"2018-06-30\",\n",
    "    \"publication_type\": \"article\",\n",
    "    \"related_identifiers\": [\n",
    "      {\n",
    "        \"identifier\": \"https://jedm.educationaldatamining.org/index.php/JEDM/article/view/210\",\n",
    "        \"relation\": \"isCitedBy\",\n",
    "        \"scheme\": \"url\"\n",
    "      }\n",
    "    ],\n",
    "    \"title\": \"Decision Tree Modeling of Wheel- Spinning and Productive Persistence in Skill Builders\",\n",
    "    \"upload_type\": \"publication\",\n",
    "    \"version\": \"1.0.1\"\n",
    "  },\n",
    "  \"modified\": \"2019-07-20T19:29:58.448673\",\n",
    "  \"owner\": 58089,\n",
    "  \"record_id\": 3344873,\n",
    "  \"state\": \"done\",\n",
    "  \"submitted\": true,\n",
    "  \"title\": \"Decision Tree Modeling of Wheel- Spinning and Productive Persistence in Skill Builders\"\n",
    "}\n",
    "```\n",
    "\n",
    "From the above JSON, we can see that we need a data source with the following:\n",
    "\n",
    "- JEDM's 'View' page for the article\n",
    "- Published PDF of the article\n",
    "- Author name\n",
    "- Author affiliation\n",
    "- Title\n",
    "- Abstract (Zenodo description)\n",
    "- Keywords\n",
    "- License\n",
    "- Language\n",
    "- Publication date\n",
    "- Publication type\n",
    "- Journal issue\n",
    "- Journal pages\n",
    "- Journal title\n",
    "- Journal volume \n",
    "\n",
    "Notably, references are not included. \n",
    "Theoretically they could be, though it is not clear that this is required, and including references would increase complexity of the process.\n",
    "\n",
    "## Obtaining Required Metadata\n",
    "\n",
    "The metadata above (without references) may be obtained in OJS 3.X from two different sources:\n",
    "\n",
    "- `Tools -> Import/Export -> PubMed XML`. Exported **per issue**, so one file per issue. XML format. **<font color=red>The plugin was trivially modified to print affilation for each author rather than just the first. Comment out line 205/208, `if ($authorIndex == 0) {`, in `ArticlePubMedXmlFilter.inc.php` </font>**\n",
    "\n",
    "- `Tools -> Report Generator -> Articles Report`. All can be exported, so one file. CSV format.\n",
    "\n",
    "**<font color=red>Accordingly, the first step is to manually download these files from OJS. If the abstracts contain \"&\", this will cause problems; replace with \"and\" </font>**\n",
    "\n",
    "The OJS exports map to the Zenodo JSON in the following way:\n",
    "\n",
    "| Zenodo                             \t| OJS                            \t| Notes                                                          \t|\n",
    "|------------------------------------\t|--------------------------------\t|----------------------------------------------------------------\t|\n",
    "| JEDM's 'View' page for the article \t| Articles report; abstractUrlMap \t| Must check url is valid                                        \t|\n",
    "| Published PDF of the article       \t| Articles report; abstractUrlMap \t| Must find download link on page and ensure PDF is downloadable \t|\n",
    "| Author name                        \t| PubMed; LastName , FirstName   \t|   \t|\n",
    "| Author affiliation                 \t| PubMed; Affiliation            \t|                             \t|\n",
    "| Title                              \t| PubMed; ArticleTitle           \t| HARDCODE TO AVOID OJS FORMATTING                                                               \t|\n",
    "| Description                        \t| Abstract                       \t|                                                                \t|\n",
    "| Keywords                           \t| Articles report; abstractKeywordMap \t| split on ',' to make array                                     \t|\n",
    "| License                            \t| always the same                \t| HARDCODE                                                               \t|\n",
    "| Language                           \t| PubMed; Language               \t|                                                                \t|\n",
    "| Publication date                   \t| PubMed; PubDate                \t| Merge year/month/day to \"2018-06-30\"                           \t|\n",
    "| Publication type                   \t| always the same                \t|                                                                \t|\n",
    "| Journal issue                      \t| PubMed; Issue                  \t|                                                                \t|\n",
    "| Journal pages                      \t| PubMed; FirstPage+LastPage     \t|                                                                \t|\n",
    "| Journal title                      \t| PubMed; JournalTitle           \t|                                                                \t|\n",
    "| Journal volume                     \t| PubMed; Volume                 \t|                                                                \t|\n",
    "\n",
    "\n",
    "### Articles Report\n",
    "\n",
    "The articles report is only used to create a mapping between article abstracts (titles are not unique, e.g. Editorial Acknowledgment) and the \n",
    "\n",
    "- corresponding URL\n",
    "- corresponding keywords\n",
    "\n",
    "We use a URL hack for this, which may break with changes to OJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r \"/z/aolney/repos/FSharp.Data.3.1.1/lib/net45/FSharp.Data.dll\"\n",
    "open FSharp.Data\n",
    "open FSharp.Data.CsvExtensions \n",
    "\n",
    "let allArticles = CsvFile.Load(\"/z/aolney/reviews/jedm/doi/articles-JEDM-20191229.csv\")\n",
    "let publishedArticles = allArticles.Filter( fun r -> r?Status = \"Published\")\n",
    "\n",
    "let abstractUrlMap =\n",
    "    publishedArticles.Rows\n",
    "    |> Seq.map( fun r -> hash(r?Abstract.Trim()),r?URL.Replace(\"https://jedm.educationaldatamining.org/index.php/JEDM/workflow/access/\",\"https://jedm.educationaldatamining.org/index.php/JEDM/article/view/\"))\n",
    "    |> Map.ofSeq\n",
    "    \n",
    "let abstractKeywordMap =\n",
    "    publishedArticles.Rows\n",
    "    |> Seq.map( fun r -> hash(r?Abstract.Trim()),(r.GetColumn \"Keyword(s)\").Replace(\", \",\",\").Split(',',System.StringSplitOptions.RemoveEmptyEntries) )\n",
    "    |> Map.ofSeq\n",
    "    \n",
    "//titleUrlMap\n",
    "//titleKeywordMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually we'll need to check these URLs are valid and download the PDF at each of them, but we defer that because we only need URLs and PDFs for a subset of these.\n",
    "\n",
    "### PubMed XML\n",
    "\n",
    "F# has compiler magic called 'type providers' that convert known file formats into objects.\n",
    "A mostly correct way to think about this is that the F# compiler is automatically deserializing data without all of the infrastructure muck that goes into it.\n",
    "While magical, type providers IMHO are buggy, especially outside of Windows. \n",
    "So using them here is easy but may introduce robustness issues.\n",
    "\n",
    "A type provider needs a sample to infer the type from, which is why we have a static XML string below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "type PubMed = XmlProvider<\"\"\"<?xml version=\"1.0\"?>\n",
    "<!DOCTYPE ArticleSet PUBLIC \"-//NLM//DTD PubMed 2.0//EN\" \"http://www.ncbi.nlm.nih.gov/entrez/query/static/PubMed.dtd\">\n",
    "<ArticleSet>\n",
    "  <Article>\n",
    "    <Journal>\n",
    "      <PublisherName/>\n",
    "      <JournalTitle>JEDM | Journal of Educational Data Mining</JournalTitle>\n",
    "      <Issn>2157-2100</Issn>\n",
    "      <Volume>11</Volume>\n",
    "      <Issue>2</Issue>\n",
    "      <PubDate PubStatus=\"epublish\">\n",
    "        <Year>2019</Year>\n",
    "        <Month>09</Month>\n",
    "        <Day>30</Day>\n",
    "      </PubDate>\n",
    "    </Journal>\n",
    "    <ArticleTitle>Editorial Acknowledgments and Introduction to the Special Issue for the EDM Journal Track</ArticleTitle>\n",
    "    <FirstPage>i</FirstPage>\n",
    "    <LastPage>i</LastPage>\n",
    "    <Language>eng</Language>\n",
    "    <AuthorList>\n",
    "      <Author>\n",
    "        <FirstName>Andrew M.</FirstName>\n",
    "        <LastName>Olney</LastName>\n",
    "        <Affiliation>University of Memphis. andrew@jedm.educationaldatamining.org</Affiliation>\n",
    "      </Author>\n",
    "      <Author>\n",
    "        <FirstName>Luke Glenn</FirstName>\n",
    "        <LastName>Eglington</LastName>\n",
    "        <Affiliation>University of Memphis. lgglngtn@memphis.edu</Affiliation>\n",
    "      </Author>\n",
    "    </AuthorList>\n",
    "    <History>\n",
    "      <PubDate PubStatus=\"received\">\n",
    "        <Year>2019</Year>\n",
    "        <Month>09</Month>\n",
    "        <Day>30</Day>\n",
    "      </PubDate>\n",
    "      <PubDate PubStatus=\"accepted\">\n",
    "        <Year>2019</Year>\n",
    "        <Month>09</Month>\n",
    "        <Day>30</Day>\n",
    "      </PubDate>\n",
    "    </History>\n",
    "    <Abstract>\n",
    "The 12th EDM Conference was held in Montr&#xE9;al from July 2 to July 5, and for the fifth time it held a Journal track which this year was edited by Andrew Olney and Luke Eglington. The Journal track allows papers submitted to JEDM to be presented at the conference. A summary is available in the proceedings, and the full text is published in the Journal. The Journal track received 7 submissions, and 2 of them made it to the final stage of the special issue for journal publication. We are pleased to publish these papers in this issue.\n",
    "</Abstract>\n",
    "  </Article>\n",
    "  <Article>\n",
    "    <Journal>\n",
    "      <PublisherName/>\n",
    "      <JournalTitle>JEDM | Journal of Educational Data Mining</JournalTitle>\n",
    "      <Issn>2157-2100</Issn>\n",
    "      <Volume>11</Volume>\n",
    "      <Issue>2</Issue>\n",
    "      <PubDate PubStatus=\"epublish\">\n",
    "        <Year>2019</Year>\n",
    "        <Month>09</Month>\n",
    "        <Day>30</Day>\n",
    "      </PubDate>\n",
    "    </Journal>\n",
    "    <ArticleTitle>Predictiveness of Prior Failures is Improved by Incorporating Trial Duration</ArticleTitle>\n",
    "    <FirstPage>1</FirstPage>\n",
    "    <LastPage>19</LastPage>\n",
    "    <Language>eng</Language>\n",
    "    <AuthorList>\n",
    "      <Author>\n",
    "        <FirstName>Luke Glenn</FirstName>\n",
    "        <LastName>Eglington</LastName>\n",
    "        <Affiliation>University of Memphis. lgglngtn@memphis.edu</Affiliation>\n",
    "      </Author>\n",
    "      <Author>\n",
    "        <FirstName>Philip I.</FirstName>\n",
    "        <LastName>Pavlik, Jr</LastName>\n",
    "        <Affiliation>University of Memphis. ppavlik@memphis.edu</Affiliation>\n",
    "      </Author>\n",
    "    </AuthorList>\n",
    "    <History>\n",
    "      <PubDate PubStatus=\"received\">\n",
    "        <Year>2018</Year>\n",
    "        <Month>12</Month>\n",
    "        <Day>21</Day>\n",
    "      </PubDate>\n",
    "      <PubDate PubStatus=\"accepted\">\n",
    "        <Year>2019</Year>\n",
    "        <Month>04</Month>\n",
    "        <Day>07</Day>\n",
    "      </PubDate>\n",
    "    </History>\n",
    "    <Abstract>\n",
    "In recent years, there has been a proliferation of adaptive learner models that seek to predict student correctness. Improvements on earlier models have shown that separate predictors for prior successes, failures, and recent performance further improve fit while remaining interpretable. However, students who engage in &#x201C;gaming&#x201D; or other off-task behaviors may reduce the predictiveness of learner models that treat counts of prior performance equivalently across gaming and non-gaming student populations. The present research evaluated how sub-groups of students that varied in their potential gaming behavior were differently fit by a logistic learner model, and whether any observed differences between sub-groups could inspire the creation of new predictors that might improve model fit. Student data extracted from a college-level online learning application were clustered according to speed and accuracy using Gaussian mixture modeling. Distinct clusters were found, with similar cluster patterns detected in three separate datasets. Subsequently, each cluster was separately fit to a Performance Factors Analysis model (PFA). Significantly different parameter coefficients across clusters implied that students more likely to have been gaming benefitted less from prior failures. These differences inspired new and modified predictors that were found to improve overall model fit - an improvement that varied in magnitude across clusters. The present findings indicate that incorporating trial duration into counts of prior failures can improve the predictive power of learning models.\n",
    "</Abstract>\n",
    "  </Article>\n",
    "  <Article>\n",
    "    <Journal>\n",
    "      <PublisherName/>\n",
    "      <JournalTitle>JEDM | Journal of Educational Data Mining</JournalTitle>\n",
    "      <Issn>2157-2100</Issn>\n",
    "      <Volume>11</Volume>\n",
    "      <Issue>2</Issue>\n",
    "      <PubDate PubStatus=\"epublish\">\n",
    "        <Year>2019</Year>\n",
    "        <Month>09</Month>\n",
    "        <Day>30</Day>\n",
    "      </PubDate>\n",
    "    </Journal>\n",
    "    <ArticleTitle>Will this Course Increase or Decrease Your GPA? Towards Grade-aware Course Recommendation</ArticleTitle>\n",
    "    <FirstPage>20</FirstPage>\n",
    "    <LastPage>46</LastPage>\n",
    "    <Language>eng</Language>\n",
    "    <AuthorList>\n",
    "      <Author>\n",
    "        <FirstName>Sara</FirstName>\n",
    "        <LastName>Morsy</LastName>\n",
    "        <Affiliation>University of Minnesota. morsy002@umn.edu</Affiliation>\n",
    "      </Author>\n",
    "      <Author>\n",
    "        <FirstName>George</FirstName>\n",
    "        <LastName>Karypis</LastName>\n",
    "        <Affiliation>University of Minnesota. karypis@umn.edu</Affiliation>\n",
    "      </Author>\n",
    "    </AuthorList>\n",
    "    <History>\n",
    "      <PubDate PubStatus=\"received\">\n",
    "        <Year>2018</Year>\n",
    "        <Month>12</Month>\n",
    "        <Day>22</Day>\n",
    "      </PubDate>\n",
    "      <PubDate PubStatus=\"accepted\">\n",
    "        <Year>2019</Year>\n",
    "        <Month>04</Month>\n",
    "        <Day>28</Day>\n",
    "      </PubDate>\n",
    "    </History>\n",
    "    <Abstract>\n",
    "In order to help undergraduate students towards successfully completing their degrees, developing tools that can assist students during the course selection process is a significant task in the education domain. The optimal set of courses for each student should include courses that help him/her graduate in a timely fashion and for which he/she is well-prepared for so as to get a good grade in. To this end, we propose two different grade-aware course recommendation approaches to recommend to each student his/her optimal set of courses. The first approach ranks the courses by using an objective function that differentiates between courses that are expected to increase or decrease a student&#x2019;s GPA. The second approach combines the grades predicted by grade prediction methods with the rankings produced by course recommendation methods to improve the final course rankings. To obtain the course rankings in both approaches, we adapt two widely-used representation learning techniques to learn the optimal temporal ordering between courses. Our experiments on a large dataset obtained from the University of Minnesota that includes students from 23 different majors show that the grade-aware course recommendation methods can do better on recommending more courses in which the students are expected to perform well and recommending fewer courses which they are expected not to perform well in than grade-unaware course recommendation methods.\n",
    "</Abstract>\n",
    "  </Article>\n",
    "</ArticleSet>\"\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can deserialize the XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "let xmlFiles = \n",
    "    System.IO.Directory.GetFiles(\"/z/aolney/reviews/jedm/doi/current-metadata\",\"*.xml\")\n",
    "    |> Array.map System.IO.File.ReadAllText\n",
    "    |> Array.map PubMed.Parse\n",
    "//(xmlFiles |> Seq.head).Articles.[0].ArticleTitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare PDF and Metadata for Zenodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to full prep our metadata before interacting with OJS.\n",
    "The required phases are:\n",
    "\n",
    "- Ensuring that we can access the View page and download PDFs from OJS\n",
    "- Creating JSON metadata from OJS metadata\n",
    "\n",
    "### Validate View pages and Download PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[||]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let AbstractHash( a : PubMed.Article ) = \n",
    "    hash(a.Abstract.Trim())\n",
    "\n",
    "let articleAbstracts = \n",
    "    xmlFiles\n",
    "    |> Array.collect( fun x -> \n",
    "        x.Articles |> Array.map( fun a -> a,AbstractHash(a) )\n",
    "    )\n",
    "    \n",
    "//validate that we can align the CSV and XML on the hashed abstract\n",
    "articleAbstracts\n",
    "|> Array.map( fun (a,abs) -> a,abstractUrlMap.TryFind(abs) )\n",
    "|> Array.filter( fun (a,abs) -> abs.IsNone )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=red>An empty list means no missing alignments. Any missing abstract alignments must be checked manually.</font>**\n",
    "\n",
    "Once we are linked between the XML and CSV via abstracts, we can check and merge URLs (in the CSV) based on abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[||]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let articleViews =\n",
    "    articleAbstracts\n",
    "    |> Array.map( fun (a,abs) -> a, abstractUrlMap.[abs] |> Http.Request)\n",
    "\n",
    "//check that all views have good responses\n",
    "articleViews \n",
    "|> Array.map snd\n",
    "|> Array.filter( fun v -> v.StatusCode <> 200 )\n",
    "|> Array.map( fun v -> v.StatusCode, v.ResponseUrl ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=red>An empty list means no missing View pages. Any URLs above that bounced are invald and must be checked manually.</font>**\n",
    "\n",
    "Once all URLs are valid, we can proceed with obtaining the PDFs from each of them.\n",
    "This is a bit awkward, because we need to find the link in the correponding View page (links do not have uniform names).\n",
    "We use the hash of the abstract as the filename of the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  Success: Early Detection of Students at Risk - Predicting Student Dropouts Using Administrative Student Data from German Universities and Machine Learning Methods\n",
       "  Success: Understanding Hybrid-MOOC Effectiveness with a Collective Socio-Behavioral Model\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for a,v in articleViews do\n",
    "    match v.Body with \n",
    "    | Text htmlText -> \n",
    "        let htmlDoc = HtmlDocument.Parse( htmlText )\n",
    "        match htmlDoc.Descendants [\"a\"] |> Seq.tryFind( fun x -> x.HasClass(\"galley-link\")) with\n",
    "        | Some pdfLinkNode ->\n",
    "            let link = pdfLinkNode.AttributeValue(\"href\")\n",
    "            Http.RequestStream(link).ResponseStream.CopyTo(new System.IO.FileStream(AbstractHash(a).ToString(),System.IO.FileMode.Create))\n",
    "            printfn \"  Success: %s\" a.ArticleTitle\n",
    "        | None -> \n",
    "            printfn \"**Failed: %i %i %s\" a.Journal.Volume a.Journal.Issue a.ArticleTitle\n",
    "    | _ ->\n",
    "        printfn \"Non-text http body indicates earlier failure\"\n",
    "articleViews.Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=red>No failed messages means links were found. Check the number of files downloaded against the number reported. Any missing links/files should be checked manually.</font>**\n",
    "\n",
    "### Creating JSON metadata from OJS metadata\n",
    "\n",
    "All the information we need is in `articleViews`. \n",
    "We just need to construct JSON appropriate for a Zenodo payload.\n",
    "To do this, we create two types:\n",
    "\n",
    "- An outer type with all information we need for Zenodo\n",
    "- An inner type, `Metadata`, that is closely aligned to Zenodo's metadata specifications\n",
    "\n",
    "The inner type we will directly serialize to json when needed.\n",
    "\n",
    "**<font color=red>Note a couple of hardcoded values at the top of the next block.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r \"/z/aolney/repos/Unidecode.NET.1.4.0/lib/net45/Unidecode.NET.dll\"\n",
    "open Unidecode.NET\n",
    "\n",
    "//NOTE: HARDCODED PROPERTIES\n",
    "let journal_title = \"Journal of Educational Data Mining\" //avoid OJS formatting of name\n",
    "let license = \"CC-BY-NC-ND-4.0\" //not present in our metadata\n",
    "let publication_type = \"article\" //Zenodo has no more appropriate category, even for editorial acknowledgments\n",
    "let upload_type = \"publication\" //everything is a publication\n",
    "let version = \"1.0.0\" //everything is the initial published version\n",
    "let access_right = \"open\" //everything is open\n",
    "\n",
    "\n",
    "type Creator =\n",
    "    {\n",
    "        affiliation: string\n",
    "        name: string\n",
    "    }\n",
    "\n",
    "type RelatedIdentifier =\n",
    "    {\n",
    "        identifier : string\n",
    "        relation : string\n",
    "        scheme : string\n",
    "    }\n",
    "    \n",
    "type Metadata =\n",
    "    {\n",
    "        access_right: string\n",
    "        creators: Creator[]\n",
    "        description: string\n",
    "        journal_issue: string\n",
    "        journal_pages: string\n",
    "        journal_title: string\n",
    "        journal_volume: string\n",
    "        keywords: string[]\n",
    "        language: string\n",
    "        license: string\n",
    "        publication_date: string\n",
    "        publication_type: string\n",
    "        related_identifiers: RelatedIdentifier[]\n",
    "        title : string\n",
    "        upload_type : string\n",
    "        version : string\n",
    "     }\n",
    "     \n",
    "//Need to wrap for Zenodo\n",
    "type ZenodoMetadata =\n",
    "    {\n",
    "        metadata : Metadata\n",
    "    }\n",
    "\n",
    "type ZenodoUpload =\n",
    "    {\n",
    "        json: ZenodoMetadata\n",
    "        filePath : string\n",
    "    }\n",
    "    \n",
    "///Sometimes the day/month is not represented with two digits (leading 0 truncated)\n",
    "let SafeDate date =\n",
    "    let dateString = date.ToString()\n",
    "    if dateString.Length = 1 then\n",
    "        \"0\" + dateString\n",
    "    else\n",
    "        dateString\n",
    "\n",
    "let zenodoUploads =\n",
    "    articleViews\n",
    "    |> Array.map( fun (a,v) ->\n",
    "        let creators = \n",
    "            a.AuthorList \n",
    "            |> Array.map( fun author -> \n",
    "                {\n",
    "                    affiliation = (author.Affiliation).ToString().Substring(0,(author.Affiliation).ToString().IndexOf(\".\"))\n",
    "                    name = author.LastName + \", \" + author.FirstName\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        let description = (a.Abstract).ToString().Trim().Unidecode()\n",
    "        let journal_issue = a.Journal.Issue.ToString()\n",
    "        //something goes wrong here and we need to go through XElement; may be b/c page numbers are both arabic and roman\n",
    "        let journal_pages = a.FirstPage.XElement.Value + \"-\" + a.LastPage.XElement.Value\n",
    "        let journal_volume = a.Journal.Volume.ToString()\n",
    "        let keywords = abstractKeywordMap.[ a |> AbstractHash ]\n",
    "        let language = a.Language\n",
    "        let publication_date = a.Journal.PubDate.Year.ToString() + \"-\" + SafeDate(a.Journal.PubDate.Month) + \"-\" + SafeDate(a.Journal.PubDate.Day)  //\"2018-06-30\",\n",
    "        let related_identifiers = [| {identifier=v.ResponseUrl; relation=\"isCitedBy\"; scheme=\"url\"} |]\n",
    "        let title = a.ArticleTitle\n",
    "        let metadata = \n",
    "            {\n",
    "                access_right = access_right\n",
    "                creators = creators\n",
    "                description = description\n",
    "                journal_issue = journal_issue\n",
    "                journal_pages = journal_pages\n",
    "                journal_title = journal_title\n",
    "                journal_volume = journal_volume\n",
    "                keywords = keywords\n",
    "                language = language\n",
    "                license = license\n",
    "                publication_date = publication_date\n",
    "                publication_type = publication_type\n",
    "                related_identifiers = related_identifiers\n",
    "                title  = title \n",
    "                upload_type  = upload_type \n",
    "                version  = version \n",
    "            }\n",
    "        { json = { metadata = metadata}; filePath = (a |> AbstractHash).ToString() }\n",
    "    )\n",
    "//zenodoUploads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Zenodo\n",
    "\n",
    "Zenodo [has a slightly quirky upload process](https://developers.zenodo.org/#rest-api) that requires the following steps:\n",
    "\n",
    "- Create an empty upload (to get an id)\n",
    "- Upload files using id (the pdf)\n",
    "- Add metadata using id\n",
    "\n",
    "For all of this, you need an access token. \n",
    "Surprisingly, both the production system and the sandbox need an access token.\n",
    "\n",
    "**<font color=red>Note sandbox/production is hardcoded.</font>**\n",
    "\n",
    "**<font color=red>We do not finalize submissions using the API. Instead we upload everything via the API, then go to the Zenodo web page, click \"Upload\", and manually check/finalize each submission.</font>**\n",
    "\n",
    "### Zenodo API\n",
    "\n",
    "This is the necessary subset of the API for our puposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "ifsharp"
   },
   "outputs": [],
   "source": [
    "#r \"/z/aolney/repos/Newtonsoft.Json.9.0.1/lib/net45/Newtonsoft.Json.dll\"\n",
    "\n",
    "open System.Text\n",
    "open FSharp.Data\n",
    "open Newtonsoft.Json\n",
    "open Newtonsoft.Json.Linq\n",
    "\n",
    "\n",
    "///For extracting id from Zenodo JSON\n",
    "type Id =\n",
    "    {\n",
    "        id : int\n",
    "    }\n",
    "    \n",
    "type Mode = \n",
    "    | Sandbox\n",
    "    | RealWorld\n",
    "\n",
    "//------------------------------------------------\n",
    "//IMPORTANT: DOIs ARE FOREVER. SANDBOX ALL TESTING\n",
    "let mode = RealWorld // Sandbox\n",
    "//------------------------------------------------\n",
    "\n",
    "//Both the real world api and sandbox require authentication tokens - you have to sign up for each separately\n",
    "let secret = (\"/z/aolney/reviews/jedm/doi/zenodo-secret\" |> System.IO.File.ReadAllLines).[0]\n",
    "let sandboxSecret = (\"/z/aolney/reviews/jedm/doi/zenodo-sandbox-secret\" |> System.IO.File.ReadAllLines).[0]\n",
    "\n",
    "let GetUrl partialPath =\n",
    "    match mode with\n",
    "    | Mode.Sandbox ->  \"https://sandbox.zenodo.org/api/\" + partialPath\n",
    "    | Mode.RealWorld -> \"https://zenodo.org/api/\" + partialPath\n",
    "\n",
    "let GetSecret() =\n",
    "    match mode with\n",
    "    | Mode.Sandbox ->  sandboxSecret\n",
    "    | Mode.RealWorld -> secret\n",
    "    \n",
    "let GetId json =\n",
    "    Newtonsoft.Json.JsonConvert.DeserializeObject<Id>(json).id\n",
    "    \n",
    "let GetIds json =\n",
    "    Newtonsoft.Json.JsonConvert.DeserializeObject<Id[]>(json)\n",
    "    |> Array.map( fun id -> id.id)\n",
    "    \n",
    "///A GET request. \n",
    "let ZenodoGet path =\n",
    "    Http.RequestString\n",
    "      ( GetUrl path, query=[\"access_token\", GetSecret(); \"size\", \"100\"], httpMethod=\"GET\" )\n",
    "      \n",
    "///A POST request with NO payload\n",
    "let ZenodoPost path = \n",
    "    Http.RequestString(\n",
    "        GetUrl path, \n",
    "        httpMethod=\"POST\",\n",
    "        query=[\"access_token\", GetSecret()]\n",
    "    )\n",
    "    \n",
    "///A POST request with JSON payload\n",
    "let ZenodoPostJson path json = \n",
    "    Http.RequestString(\n",
    "        GetUrl path, \n",
    "        headers = [ HttpRequestHeaders.ContentType HttpContentTypes.Json ],\n",
    "        query=[\"access_token\", GetSecret()], \n",
    "        body = TextRequest json\n",
    "    )\n",
    "    \n",
    "///A PUT request with JSON payload\n",
    "let ZenodoPutJson path json = \n",
    "    Http.RequestString(\n",
    "        GetUrl path, \n",
    "        httpMethod = \"PUT\",\n",
    "        headers = [\n",
    "            HttpRequestHeaders.ContentType HttpContentTypes.Json \n",
    "            HttpRequestHeaders.ContentEncoding \"utf-8\" ],\n",
    "        query=[\"access_token\", GetSecret()], \n",
    "        body = TextRequest json\n",
    "    )\n",
    "\n",
    "\n",
    "///A POST request with file payload\n",
    "let ZenodoPostFile urlPath filePath = \n",
    "    let data = System.IO.File.OpenRead(filePath) :> System.IO.Stream\n",
    "    Http.RequestString(\n",
    "        GetUrl urlPath, \n",
    "        query=[\"access_token\", GetSecret()], \n",
    "        body = Multipart(\n",
    "            boundary = \"---SuperAwesomeFormBoundary\", \n",
    "            parts = [\n",
    "                MultipartItem(\"file\", (System.IO.Path.GetFileName(filePath) + \".pdf\"), data)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "///A DELETE request\n",
    "let ZenodoDelete path = \n",
    "    Http.RequestString(\n",
    "        GetUrl path, \n",
    "        httpMethod = \"DELETE\",\n",
    "        query=[\"access_token\", GetSecret()]\n",
    "        //body = TextRequest \"\"\n",
    "    )\n",
    "\n",
    "//-----------------------------------------------------------------------\n",
    "// Convienence wrapper functions\n",
    "\n",
    "///Get a listing of all depositions\n",
    "let ZenodoGetDepositionList() = ZenodoGet \"deposit/depositions\"\n",
    "\n",
    "///Unlock a published deposition for editing\n",
    "let ZenodoEditArticle id =\n",
    "    ZenodoPost (\"deposit/depositions/\" + id.ToString() + \"/actions/edit\")\n",
    "\n",
    "///Create an article entry; the ID is used for updating it\n",
    "let ZenodoCreateEmptyArticle() = ZenodoPostJson \"deposit/depositions\" \"{}\"\n",
    "    \n",
    "///Update an article entry with metadata, using an ID\n",
    "let ZenodoUpdateArticle id (json:string) =\n",
    "    ZenodoPutJson (\"deposit/depositions/\" + id.ToString()) json\n",
    "    \n",
    "///Attach a file to an article entry\n",
    "let ZenodoUploadArticleFile id filePath =\n",
    "    ZenodoPostFile (\"deposit/depositions/\" + id.ToString() + \"/files\") filePath\n",
    "    \n",
    "///Delete an entry for an ID\n",
    "let ZenodoDeleteId id =\n",
    "    ZenodoDelete (\"deposit/depositions/\" + id.ToString())\n",
    "    |> ignore\n",
    "   \n",
    "///Delete all unpublished entries\n",
    "let ZenodoDeleteAll() =\n",
    "    let mutable notDone = true\n",
    "    while notDone do\n",
    "        let ids = ZenodoGet \"deposit/depositions\" |> GetIds\n",
    "        printfn \"Deleting %A\" ids\n",
    "        try\n",
    "            ids |> Array.iter ZenodoDeleteId\n",
    "        with\n",
    "        | _ -> ()\n",
    "        if ids.Length = 0 then notDone <- false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload OJS submissions to Zenodo\n",
    "\n",
    "If needed, delete all unpublished entries to clean up previous failed runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deleting [|424949; 424947; 424945; 424943; 424941; 424939; 424937; 424935; 424933; 424931;\n",
       "  424929; 424927; 424925; 424923; 424921; 424919; 424917; 424915; 424913; 424911;\n",
       "  424909; 424907; 424905; 424903; 424901; 424899; 424897; 424895; 424893; 424891;\n",
       "  424889; 424887; 424885; 424883; 424881; 424879; 424877; 424875; 424873; 424871;\n",
       "  424869; 424867; 424865; 424863; 424861; 424859; 424857; 424855; 424853; 424851;\n",
       "  424849; 424847; 424845; 424843; 424841; 424839; 424837; 424835; 424833; 424831;\n",
       "  424829; 424827; 424825; 424823; 424821; 424819; 424817; 424815; 424813; 424811;\n",
       "  424809; 424807; 424805; 424803; 424801; 424799; 424797; 424795; 424793|]\n",
       "Deleting [|424793|]\n",
       "Deleting [||]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ZenodoDeleteAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "> Success: 11 3 Early Detection of Students at Risk - Predicting Student Dropouts Using Administrative Student Data from German Universities and Machine Learning Methods\n",
       "> Success: 11 3 Understanding Hybrid-MOOC Effectiveness with a Collective Socio-Behavioral Model\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for z in zenodoUploads do\n",
    "    //issues with bad formatting, so force ASCII\n",
    "    let json = Newtonsoft.Json.JsonConvert.SerializeObject(z.json,Newtonsoft.Json.Formatting.Indented).Unidecode()\n",
    "    let id = ZenodoCreateEmptyArticle() |> GetId\n",
    "    try\n",
    "        let fileStatus = ZenodoUploadArticleFile id z.filePath\n",
    "        let metaStatus = ZenodoUpdateArticle id json\n",
    "        printfn \"> Success: %s %s %s\"  z.json.metadata.journal_volume  z.json.metadata.journal_issue z.json.metadata.title\n",
    "    with\n",
    "    | _ -> \n",
    "        printfn \"***********************************\"\n",
    "        printfn \"> FAILED ON ID: %i\\n%s\" id json\n",
    "        printfn \"***********************************\"\n",
    "   \n",
    "//printfn \"> Processing title: %s\" z.json.metadata.title\n",
    "//printfn \"> Created id: %i\" id\n",
    "//printfn \"> Uploaded file: %s\" z.filePath\n",
    "//printfn \"> Uploaded metadata:\\n%s\" (Newtonsoft.Json.JsonConvert.SerializeObject(z.json, Newtonsoft.Json.Formatting.Indented))\n",
    "//printfn \"-------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=red>If failures, then modify code and rerun or correct manually.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "At this point we are almost done. The only things remaining are:\n",
    "\n",
    "- Manually check each entry in Zenodo, then publish to Zenodo\n",
    "- Update OJS with the corresponding DOI from Zenodo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST HOC FIX\n",
    "\n",
    "The original version of this script did not use the \".pdf\" file extension.\n",
    "The following code adds a note to each DOI explaining how to open the file.\n",
    "\n",
    "**This is a template for any posthoc modification to the deposition record EXCEPT changing the underlying file, which is not allowed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The result of this expression has type 'string' and is implicitly ignored. Consider using 'ignore' to discard this value explicitly, e.g. 'expr |> ignore', or 'let' to bind the result to a name, e.g. 'let result = expr'.\n",
      "This expression is a function value, i.e. is missing arguments. Its type is string -> unit."
     ]
    },
    {
     "data": {
      "text/plain": [
       "> Success: 3554752\n",
       "***********************************\n",
       "***********************************\n",
       "> Success: 3554594\n",
       "> Success: 3554596\n",
       "> Success: 3554598\n",
       "> Success: 3554600\n",
       "> Success: 3554602\n",
       "> Success: 3554604\n",
       "> Success: 3554606\n",
       "> Success: 3554608\n",
       "> Success: 3554610\n",
       "> Success: 3554612\n",
       "> Success: 3554614\n",
       "> Success: 3554616\n",
       "> Success: 3554618\n",
       "> Success: 3554620\n",
       "> Success: 3554622\n",
       "> Success: 3554624\n",
       "> Success: 3554626\n",
       "> Success: 3554628\n",
       "> Success: 3554630\n",
       "> Success: 3554632\n",
       "> Success: 3554634\n",
       "> Success: 3554636\n",
       "> Success: 3554638\n",
       "> Success: 3554640\n",
       "> Success: 3554642\n",
       "> Success: 3554644\n",
       "> Success: 3554646\n",
       "> Success: 3554648\n",
       "> Success: 3554650\n",
       "> Success: 3554654\n",
       "> Success: 3554656\n",
       "> Success: 3554658\n",
       "> Success: 3554660\n",
       "> Success: 3554662\n",
       "> Success: 3554664\n",
       "> Success: 3554666\n",
       "> Success: 3554668\n",
       "> Success: 3554670\n",
       "> Success: 3554672\n",
       "> Success: 3554676\n",
       "> Success: 3554678\n",
       "> Success: 3554680\n",
       "> Success: 3554682\n",
       "> Success: 3554684\n",
       "> Success: 3554686\n",
       "> Success: 3554688\n",
       "> Success: 3554690\n",
       "> Success: 3554692\n",
       "> Success: 3554694\n",
       "***********************************\n",
       "***********************************\n",
       "> Success: 3554698\n",
       "> Success: 3554702\n",
       "> Success: 3554704\n",
       "> Success: 3554706\n",
       "> Success: 3554708\n",
       "***********************************\n",
       "***********************************\n",
       "> Success: 3554712\n",
       "> Success: 3554734\n",
       "***********************************\n",
       "***********************************\n",
       "> Success: 3554714\n",
       "> Success: 3554716\n",
       "> Success: 3554718\n",
       "> Success: 3554720\n",
       "> Success: 3554722\n",
       "> Success: 3554724\n",
       "> Success: 3554726\n",
       "> Success: 3554728\n",
       "> Success: 3554730\n",
       "> Success: 3554732\n",
       "> Success: 3554736\n",
       "> Success: 3554738\n",
       "> Success: 3554740\n",
       "> Success: 3554742\n",
       "> Success: 3554746\n",
       "> Success: 3554748\n",
       "> Success: 3554750\n",
       "***********************************\n",
       "***********************************\n",
       "***********************************\n",
       "***********************************\n",
       "> Success: 3344873\n",
       "***********************************\n",
       "***********************************\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type Note =\n",
    "    {\n",
    "        notes : string\n",
    "    }\n",
    "\n",
    "type Creator =\n",
    "    {\n",
    "        affiliation: string\n",
    "        name: string\n",
    "    }\n",
    "\n",
    "type RelatedIdentifier =\n",
    "    {\n",
    "        identifier : string\n",
    "        relation : string\n",
    "        scheme : string\n",
    "    }\n",
    "\n",
    "type Metadata2 =\n",
    "    {\n",
    "        access_right: string\n",
    "        creators: Creator[]\n",
    "        description: string\n",
    "        journal_issue: string\n",
    "        journal_pages: string\n",
    "        journal_title: string\n",
    "        journal_volume: string\n",
    "        keywords: string[]\n",
    "        language: string\n",
    "        license: string\n",
    "        publication_date: string\n",
    "        publication_type: string\n",
    "        related_identifiers: RelatedIdentifier[]\n",
    "        title : string\n",
    "        upload_type : string\n",
    "        version : string\n",
    "        notes : string\n",
    "     }\n",
    "     \n",
    "//Need to wrap for Zenodo\n",
    "type ZenodoMetadata2 =\n",
    "    {\n",
    "        metadata : Metadata2\n",
    "    }\n",
    "\n",
    "    \n",
    "let ids = ZenodoGetDepositionList() |> GetIds\n",
    "\n",
    "for id in ids do\n",
    "    try\n",
    "        let currentJson = ZenodoEditArticle id\n",
    "        let currentZenodoMetadata = Newtonsoft.Json.JsonConvert.DeserializeObject<ZenodoMetadata2>(currentJson)\n",
    "        let newMetadata = {currentZenodoMetadata.metadata with notes=\"The file is in PDF format. If your computer does not recognize it, simply download the file and then open it with your browser.\" }\n",
    "        let newJson = Newtonsoft.Json.JsonConvert.SerializeObject({metadata = newMetadata})\n",
    "        ZenodoUpdateArticle id newJson |> ignore\n",
    "        printfn \"> Success: %i\"  id\n",
    "    with\n",
    "    | _ -> \n",
    "        printfn \"***********************************\"\n",
    "        printfn \"> FAILED ON ID: %i\\n%s\" id\n",
    "        printfn \"***********************************\"\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "F#",
   "language": "fsharp",
   "name": "ifsharp"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "ifsharp",
     "ifsharp",
     "",
     ""
    ]
   ],
   "version": "0.9.15.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
